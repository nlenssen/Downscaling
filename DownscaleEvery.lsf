#!/bin/csh
#
# $Id: DownscaleEvery.lsf,v 1.14 2008/05/02 15:45:37 thoar Exp $
#
#BXXX -b 22:30
#BXXX -J "downscale[1-13]"
#BXXX -J "downscale[1-13]%7"
#BSUB -J "downscale[1]"
#BSUB -o downscale.%J.%I.log
#BSUB -q standby
#BSUB -N -u ${USER}@ucar.edu
#BSUB -n 1
#BSUB -W 7:00
#BSUB -m  "cr0128en cr0129en cr0130en cr0131en cr0132en cr0133en cr0134en cr0135en cr0136en cr0137en cr0138en cr0139en cr0140en cr0141en cr0202en cr0201en"
#
#----------------------------------------------------------------------
# End of script preamble.
#----------------------------------------------------------------------

if ($?LSB_HOSTS) then

   setenv ORIGINALDIR $LS_SUBCWD 
   setenv JOBNAME     $LSB_OUTPUTFILE:ar
   setenv JOBID       $LSB_JOBID
   setenv MYQUEUE     $LSB_QUEUE
   setenv MYHOST      $LSB_SUB_HOST
   setenv TASKID      $LSB_JOBINDEX
   setenv NTASKS      $LSB_JOBINDEX_END
   setenv TEMPDIR     /tmp/${user}
   setenv DATADIR     /ptmp/${user}/downscaling

else

   # You can debug the script by running this interactively.

   setenv ORIGINALDIR `pwd`
   setenv JOBNAME     downscale
   setenv JOBID       $$
   setenv MYQUEUE     Interactive
   setenv MYHOST      $host
   setenv TASKID      2
   setenv NTASKS      3
   setenv TEMPDIR     /project/gsp/${user}
   setenv DATADIR     /project/gsp/${user}/downscaling

endif

#----------------------------------------------------------------------
# Set up the arrays that will be exploited by the Job Array ID 
#----------------------------------------------------------------------

set  startyears = (2000 2010 2020 2030 2040 2050 2060 2070 2080 2090)
set    endyears = (2009 2019 2029 2039 2049 2059 2069 2079 2089 2099)

set  startyears = (1870 1880 1890 1900 1910 1920 1930 1940 1950 1960 1970 1980 1990)
set    endyears = (1879 1889 1899 1909 1919 1929 1939 1949 1959 1969 1979 1989 1999)

set year1 = $startyears[$TASKID]
set yearN = $endyears[$TASKID]   

#----------------------------------------------------------------------
# List of all candidate files to be downscaled for this experiment
# lrfname ... "Low Res filename"
#----------------------------------------------------------------------

set prismvar = ppt
set   gcmvar = pr

setenv ddir /fs/image/home/thoar/downscaling/gcm
setenv ddir          /ptmp/thoar/downscaling/PR

set lrfname = ${gcmvar}_A1.20C3M_1.CCSM.atmm.1870-01_cat_1999-12.nc
set lrfname = ${gcmvar}_A1.20C3M_2.CCSM.atmm.1870-01_cat_1999-12.nc
set lrfname = ${gcmvar}_A1.20C3M_3.CCSM.atmm.1870-01_cat_1999-12.nc
set lrfname = ${gcmvar}_A1.20C3M_4.CCSM.atmm.1870-01_cat_1999-12.nc
set lrfname = ${gcmvar}_A1.20C3M_5.CCSM.atmm.1870-01_cat_1999-12.nc
set lrfname = ${gcmvar}_A1.20C3M_6.CCSM.atmm.1870-01_cat_1999-12.nc
set lrfname = ${gcmvar}_A1.20C3M_7.CCSM.atmm.1870-01_cat_1999-12.nc
set lrfname = ${gcmvar}_A1.20C3M_9.CCSM.atmm.1870-01_cat_1999-12.nc
set lrfname = ${gcmvar}_A1.20C3M_EA1-5.CCSM.atmm.1870-01_cat_1999-12.nc

# Pick an input file and create the corresponding output file 
# that reflects the fact we're only doing 10 years here.

set lrfname = ${gcmvar}_A1.20C3M_8.CCSM.atmm.1870-01_cat_1999-12.nc

echo "working on $lrfname decade ${TASKID} at "`date`
echo "running on $host in queue ${MYQUEUE}"

# Pick an input file and create the corresponding output file 
# that reflects the fact we're only doing 10 years here.

set OFNAME = `echo $lrfname | sed -e "s#2000#$year1#"`
set OFNAME = `echo  $OFNAME | sed -e "s#2099#$yearN#"`
set YEARARR = "(2000:2099)"

set OFNAME = `echo $lrfname | sed -e "s#1870#$year1#"`
set OFNAME = `echo  $OFNAME | sed -e "s#1999#$yearN#"`
set OFNAME = `echo  $OFNAME | sed -e "s#${gcmvar}_#${prismvar}_#"`
set YEARARR = "(1870:1999)"

set OUTPUTBASE = ${OFNAME:r}.downscaled

set EXP = $lrfname:r
set EXP = $EXP:r
set EXP = $EXP:r
set EXP = $EXP:r
set EXP = $EXP:e

#----------------------------------------------------------------------
# Create a clean temporary directory, work in it, and clean up when done.
#----------------------------------------------------------------------

setenv TMPDIR ${TEMPDIR}/${JOBNAME}_${EXP}_job${TASKID}

mkdir -p ${TMPDIR}
cd ${TMPDIR}

#----------------------------------------------------------------------
# Just an echo of job attributes
# I am also leaving a trail of breadcrumbs in case the job fails.
# I'll be able to track which node was being used when it failed.
#----------------------------------------------------------------------

echo
echo "${JOBNAME} ($JOBID) submitted   from $ORIGINALDIR"
echo "${JOBNAME} ($JOBID) submitted   from $MYHOST"
echo "${JOBNAME} ($JOBID) running in queue $MYQUEUE"
echo "${JOBNAME} ($JOBID) running       on $host"
echo "${JOBNAME} ($JOBID) job $TASKID of $NTASKS started at "`date`
echo

echo "${JOBNAME} ($JOBID) submitted   from $ORIGINALDIR"            >! breadcrumb
echo "${JOBNAME} ($JOBID) submitted   from $MYHOST"                 >> breadcrumb
echo "${JOBNAME} ($JOBID) running in queue $MYQUEUE"                >> breadcrumb
echo "${JOBNAME} ($JOBID) running       on $host"                   >> breadcrumb
echo "${JOBNAME} ($JOBID) job $TASKID of $NTASKS started at "`date` >> breadcrumb

#----------------------------------------------------------------------
# Create the R program to run
#
# rather remarkably ... it was taking more than 30 minutes to create a netcdf
# file of 10 years ... and it takes less than a minute to do it for 1 year.
# So ... I might just process every year independently and ncrcat them together.
# the problem is that the high-water memory mark for a 400MB netCDF file
# is over 4GB ... crud.
#
# The output is EXPLICITLY created in the final resting place, so it does
# not need to be moved.
#----------------------------------------------------------------------

echo "   year1    = $year1"          >! ${JOBNAME}.${JOBID}.${TASKID}.r
echo "   yearN    = $yearN"          >> ${JOBNAME}.${JOBID}.${TASKID}.r
echo '   prismvar = "'$prismvar'"'   >> ${JOBNAME}.${JOBID}.${TASKID}.r
echo '   gcmvar   = "'$gcmvar'"'     >> ${JOBNAME}.${JOBID}.${TASKID}.r
echo '   fname    = "'$lrfname'"'    >> ${JOBNAME}.${JOBID}.${TASKID}.r
echo '   fbase    = "'$OUTPUTBASE'"' >> ${JOBNAME}.${JOBID}.${TASKID}.r
echo '   ddir     = "'$ddir'"'       >> ${JOBNAME}.${JOBID}.${TASKID}.r
echo '   dircoeff = "'$DATADIR'"'    >> ${JOBNAME}.${JOBID}.${TASKID}.r
echo "   yeararr  = $YEARARR"        >> ${JOBNAME}.${JOBID}.${TASKID}.r

cat << ENDofTask01 >> ${JOBNAME}.${JOBID}.${TASKID}.r

   library(fields)
   library(ncdf)

   source("/fs/image/home/thoar/downscaling/GetPredDomain.r")
   source("/fs/image/home/thoar/downscaling/CoeffsEveryToRData.r")
   source("/fs/image/home/thoar/downscaling/SimpleRDataToNetCDF.r")

   ofname = sprintf("%s/%s.RData",dircoeff,fbase)
   ofname = sprintf("%s/%s.RData",".",fbase)

   ddata = CoeffsEveryToRData( year1      = year1,
                               yearN      = yearN,
                               prismvar   = prismvar,
                               coarsevar  = gcmvar,
                               coarsefile = fname,
                               ddir       = ddir,
                               dircoeff   = dircoeff,
                               yeararr    = yeararr)

   save(ddata,file=ofname)

#  load( ofname )
   ofname = paste(fbase,".nc",sep="")
   bob = SimpleRDataToNetCDF(vrbl = ddata,
                             ddir = ".",
                             file = ofname)

ENDofTask01
   
#----------------------------------------------------------------------
# Run the program:
#----------------------------------------------------------------------
R CMD BATCH --no-save ${JOBNAME}.${JOBID}.${TASKID}.r \
                      ${JOBNAME}.${JOBID}.${TASKID}.rout
   
#----------------------------------------------------------------------
# Copy the output back to where we started, remove temporary directory.
#----------------------------------------------------------------------

mv ${JOBNAME}.${JOBID}.${TASKID}.r    ${ORIGINALDIR}
mv ${JOBNAME}.${JOBID}.${TASKID}.rout ${ORIGINALDIR}
mv ${OUTPUTBASE}.RData                ${DATADIR}
mv ${OUTPUTBASE}.nc                   ${DATADIR}

ls -alh 

cd ${ORIGINALDIR}
\rm -rf ${TMPDIR}

echo ""
echo "${JOBNAME} ($JOBID) job $TASKID of $NTASKS finished at "`date`
echo ""

#----------------------------------------------------------------------
# LSF options for BSUB
#
### -J      job name 
### -o      output listing filename 
### -q      queue
### -N -u   mail this user when job finishes
### -n      number of processors  (really)
### -W      wall-clock hours:minutes required
### -b      [[month:]day:]hour:minute "Dispatches the job for 
###         execution on or after the specified date and time. The date 
###         and time are in the form of [[month:]day:]hour:minute where 
###         the number ranges are as follows:
###         month 1-12, day 1-31, hour 0-23, minute 0-59.
#
#----------------------------------------------------------------------

exit
